{"meta":{"title":"Notes","subtitle":"","description":"好记性不如烂笔头。","author":"Yang","url":"http://www.yq194.top"},"pages":[{"title":"","date":"2018-01-02T09:14:21.000Z","updated":"2017-01-24T06:50:16.000Z","comments":true,"path":"404.html","permalink":"http://www.yq194.top/404.html","excerpt":"","text":"404"},{"title":"","date":"2017-01-24T07:28:01.000Z","updated":"2017-04-08T05:58:28.000Z","comments":true,"path":"about/index.html","permalink":"http://www.yq194.top/about/index.html","excerpt":"","text":"据我们所知，我们已经知道一些，我们知道我们已经知道一些，我们还知道，我们有些并不知道，也就是说，我们知道有些事情我们还不知道，但是，还有一些，我们并不知道我们不知道，这些我们不知道的，我们不知道 Mr’ Yang"},{"title":"分类","date":"2018-01-03T08:39:27.000Z","updated":"2018-01-03T08:39:27.000Z","comments":true,"path":"categories/index.html","permalink":"http://www.yq194.top/categories/index.html","excerpt":"","text":""},{"title":"常用标签","date":"2018-01-03T08:40:36.000Z","updated":"2018-01-03T08:40:36.000Z","comments":true,"path":"tags/index.html","permalink":"http://www.yq194.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java常用日志框架配置文件详解","slug":"Java常用日志框架配置文件详解","date":"2018-03-05T10:28:32.000Z","updated":"2018-03-07T08:51:28.000Z","comments":true,"path":"2018/03/05/Java常用日志框架配置文件详解/","link":"","permalink":"http://www.yq194.top/2018/03/05/Java常用日志框架配置文件详解/","excerpt":"Java常用日志框架配置文件详解 用来记录日志文件配置及结构，使用时便于查询 日志体系整合请看这里","text":"Java常用日志框架配置文件详解 用来记录日志文件配置及结构，使用时便于查询 日志体系整合请看这里 1.Log4j日志及配置文件详解在应用程序中添加日志记录总的来说基于三个目的: 监视代码中变量的变化情况，周期性的记录到文件中供其他应用进行统计分析工作 跟踪代码运行时轨迹，作为日后审计的依据; 担当集成开发环境中的调试器的作用 向文件或控制台打印代码的调试信息。 Apache组织为我们提供了一个强有力的日志操作包 Log4j。 Log4j组成结构: 相当于配置文件业说，Log4j有3个方面的内容: （1）根目录(级别和目的地); （2）目的地(控制台、文件等等); （3）输出样式。 ![log_three_compont]/images/log_three_compont.png) 完整的类结构如下: Logger - 日志写出器，供输出日志信息,注意这里的RootCategory以前的配置中使用，现在都使用RootLogger配置。Appender - 日志目的地，把格式化好的日志信息输出到指定的地方（常用的如下）: ConsoleAppender - 目的地为控制台的 Appender FileAppender - 目的地为文件的 Appender RollingFileAppender - 目的地为大小受限的文件的 Appender DailyRollingFileAppender - 目的地为每一周期(天/周/月)的文件的Appender AsyncAppender - 异步的Appender Layout - 日志格式化器，用来把logging request 格式化成字符串 PatternLayout - 用指定的 pattern 格式化 logging request 的 Layout,有如下Layout:HTMLLayout,PatternLayout,SimpleLayout,TTCCLayout,XMLLayout Log4j基于Properties的日志配置详解: Log4j 支持两种配置文件格式，Log4j 支持两种配置文件格式，一种是 XML 格式的文件，一种是 properties(key=value)文件。一个简单Properties的配置示例如下: 123456789101112131415161718192021log4j.rootLogger=INFO, stdout , Rlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=[QC] %p [%t] %C.%M(%L) | %m%nlog4j.appender.R=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.R.File=logs/sys_log.loglog4j.appender.R.layout=org.apache.log4j.PatternLayoutlog4j.appender.R.layout.ConversionPattern=%d-[TS] %p %t %c - %m%nlog4j.logger.org.apache.commons=ERRORlog4j.logger.org.apache.struts=WARNlog4j.logger.org.displaytag=ERRORlog4j.logger.org.springframework=DEBUGlog4j.logger.com.ibatis.db=WARNlog4j.logger.org.apache.velocity=FATALlog4j.logger.com.canoo.webtest=WARNlog4j.logger.org.hibernate.ps.PreparedStatementCache=WARNlog4j.logger.org.hibernate=DEBUG （1）配置根 Logger，其语法为:log4j.rootLogger=level,appenderName1,appenderName2, ...，其中，level 是日志记录的优先级，分为 OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL 或者您定义 的级别。Log4j 建议只使用四个级别，优先级从高到低分别是 ERROR、WARN、INFO、DEBUG。通过在这里定义的 级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定义了 INFO 级别，则应用程序中所有 DEBUG 级别的日志信息将不被打印出来。 appenderName 就是指 B 日志信息输出到哪个地方。您可以同时指定多 个输出目的地。优先级:ALL &lt; DEBUG &lt; INFO &lt;WARN &lt; ERROR &lt; FATAL &lt; OFF。 （2）配置日志信息输出目的地 Appender，其语法为: 12log4j.appender.appenderName = Log4j提供的appender类 log4j.appender.appenderName.属性名 = 属性值 log4j.appender.appenderName.属性名 = 属性值 其中，Log4j 提供的常用的 appender 有以下几种: 12345org.apache.log4j.ConsoleAppender(控制台)org.apache.log4j.FileAppender(文件) org.apache.log4j.DailyRollingFileAppender(每天产生一个日志文件) org.apache.log4j.RollingFileAppender(文件大小到达指定尺寸的时候产生一个新的文件)org.apache.log4j.WriterAppender(将日志信息以流格式发送到任意指定的地方) ConsoleAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是 true,意谓着所有的消息都会被立即输出。 Target=System.err:默认情况下是:System.out,指定输出控制台 FileAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是 true,意谓着所有的消息都会被立即输出。 File=mylog.txt:指定消息输出到 mylog.txt 文件。 Append=false:默认值是 true,即将消息增加到指定文件中，false 指将消息覆盖指定的文件内容 DailyRollingFileAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是 true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到 mylog.txt 文件。 Append=false:默认值是 true,即将消息增加到指定文件中，false 指将消息覆盖指定的文件内容。 DatePattern=&#39;&#39;.&#39;&#39;yyyy-ww:每周滚动一次文件，即每周产生一个新的文件。 当然也可以指定按月、周、天、时和分。即对应的格式如下: 1). ‘’.’’yyyy-MM: 每月 2). ‘’.’’yyyy-ww: 每周 3). ‘’.’’yyyy-MM-dd: 每天 4). ‘’.’’yyyy-MM-dd-a: 每天两次 5). ‘’.’’yyyy-MM-dd-HH: 每小时 6). ‘’.’’yyyy-MM-dd-HH-mm: 每分钟 DatePattern=&#39;&#39;.&#39;&#39;yyyy-ww:每周滚动一次文件，即每周产生一个新的文件。 当然也可以指定按月、周、天、时和分。即对应的格式如下: RollingFileAppender 选项 Threshold=WARN:指定日志消息的输出最低层次。 ImmediateFlush=true:默认值是 true,意谓着所有的消息都会被立即输出。 File=mylog.txt:指定消息输出到 mylog.txt 文件。 Append=false:默认值是 true,即将消息增加到指定文件中，false 指将消息覆盖指定的文件内容。 MaxFileSize=100KB: 后缀可以是 KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到 mylog.log.1 文件。 MaxBackupIndex=2:指定可以产生的滚动文件的最大数。 配置日志信息的格式(布局)，其语法为: 12log4j.appender.appenderName.layout = Log4j提供的layout类 log4j.appender.appenderName.layout.属性 = 值 log4j.appender.appenderName.layout.属性 = 值 其中，Log4j 提供的 layout 有以下几种: 12345org.apache.log4j.HTMLLayout(以 HTML 表格形式布局)org.apache.log4j.PatternLayout(可以灵活地指定布局模式)org.apache.log4j.SimpleLayout(包含日志信息的级别和信息字符串)org.apache.log4j.TTCCLayout(包含日志产生的时间、线程、类别等等信息)org.apache.log4j.XMLLayout(以XML文件形式，好像用的较少) 1) HTMLLayout 选项 LocationInfo=true:默认值是 false,输出 java 文件名称和行号 Title=my app file: 默认值是 Log4J Log Messages. 2) PatternLayout 选项 ConversionPattern=%m%n :指定怎样格式化指定的消息。 3) XMLLayout 选项 LocationInfo=true:默认值是 false,输出 java 文件和行号Log4J 采用类似 C 语言中的 printf 函数的打印格式格式化日志信息，打印参数如下: 这里需要说明的就是日志信息格式中几个符号所代表的含义:-X号: X信息输出时左对齐;%p: 输出日志信息优先级，即 DEBUG，INFO，WARN，ERROR，FATAL,%d: 输出日志时间点的日期或时间，默认格式为 ISO8601，也可以在其后指定格式，比如:%d{yyy MMM dd HH:mm:ss,SSS}，输出类似:2002 年 10 月 18 日 22:10:28，921 %r: 输出自应用启动到输出该 log 信息耗费的毫秒数%c: 输出日志信息所属的类目，配置文件中的名字，通常就是所在类的全名(若使用 rootLogger) %t: 输出产生该日志事件的线程名%l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及行数。 举例:Testlog4.main(TestLog4.java:10)%x: 输出和当前线程相关联的 NDC(嵌套诊断环境)，尤其用到像 java servlets 这样的多客户多线程的应 用中。%%: 输出一个”%”字符%F: 输出日志消息产生时所在的文件名称%L: 输出代码中的行号%m: 输出代码中指定的消息,产生的日志具体信息%n: 输出一个回车换行符，Windows 平台为”\\r\\n”，Unix 平台为”\\n”输出日志信息换行%M: 输出日志信息所属的方法 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如:og4j.appender.A1.layout.ConversionPattern=%-4r %-5p %d{yyyy-MM-dd HH:mm:ssS} %c %m%n 1).%20c:指定输出 category 的名称，最小的宽度是 20，如果 category 的名称小于 20 的话，默认的情 况下右对齐。2).%-20c:指定输出 category 的名称，最小的宽度是 20，如果 category 的名称小于 20 的话，”-“号指 定左对齐。3).%.30c:指定输出 category 的名称，最大的宽度是 30，如果 category 的名称大于 30 的话，就会将左 边多出的字符截掉，但小于 30 的话也不会有空格。4).%20.30c:如果 category 的名称小于 20 就补空格，并且右对齐，如果其名称长于 30 字符，就从左边交 远销出的字符截掉 这里需要注意的一个地方是Appender中的 Threshold=WARN配置：与rootLogger中的level有区别，假如Threshold=WARN（ALL &lt; DEBUG &lt; INFO &lt;WARN &lt; ERROR &lt; FATAL &lt; OFF）那么DEBUG,INFO不会输出，即使是level配置了INFO。这样子在日志分级输出成不同文件时很有用，比如error打印到A文件，info打印到B文件 2.Log4j基于XML的日志配置详解:xml 格式的 log4j 配置文件需要使用org.apache.log4j.html.DOMConfigurator.configure()方法 来读入。对 xml 文件的语法定义可以在 log4j 的发布包中找到:org/apache/log4j/xml/log4j.dtd。log4j 的 xml 配置文件的树状结构如下所示，注意下图只显示了常用的部分。 xml 配置文件的头部包括两个部分:xml 声明和 dtd 声明,详细元数据解析如下： 1&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE log4j:configuration SYSTEM &quot;log4j.dtd&quot;&gt; 12log4j:configuration (root element) xmlns:log4j [#FIXED attribute] 定义 log4j 的名字空间，取定值&quot;http://jakarta.apache.org/log4j/&quot; appender [* child] : 一个 appender 子元素定义一个日志输出目的地 logger [* child] : 一个 logger 子元素定义一个日志写出器 root [? child] : root子元素定义了root logger 1234appender 元素定义一个日志输出目的地。 name [#REQUIRED attribute] : 定义 appender 的名字，以便被后文引用 class [#REQUIRED attribute] : 定义 appender 对象所属的类的全名 param [* child] : 创建 appender 对象时传递给类构造方法的参数 layout [? child] : 该 appender 使用的 layout 对象 12layout 元素定义与某一个 appender 相联系的日志格式化器。 class [#REQUIRED attribute] : 定义 layout 对象所属的类的全名param [* child] : 创建 layout 对象时传递给类构造方法的参数 12logger 元素定义一个日志输出器。 name [#REQUIRED attribute] : 定义 logger 的名字，以便被后文引用 additivity [#ENUM attribute] : 取值为&quot;true&quot;(默认)或者&quot;false&quot;，是否继承父 logger 的属性 level [? child] : 定义该 logger 的日志级别 appender-ref [* child] : 定义该 logger 的输出目的地 12root元素定义根日志输出器root logger。 param [* child] : 创建 root logger 对象时传递给类构造方法的参数 level [? child] : 定义 root logger 的日志级别 appender-ref [* child] : 定义 root logger 的输出目的地 1level 元素定义 logger 对象的日志级别。 class [#IMPLIED attribute] : 定义 level 对象所属的类，默认情况下是&quot;org.apache.log4j.Level&quot;类 value [#REQUIRED attribute] : 为 level 对象赋值。可能的取值从小到大依次为&quot;all&quot;、&quot;debug&quot;、&quot;info&quot;、&quot;warn&quot;、&quot;error&quot;、&quot;fatal&quot;和&quot;off&quot;。当值为&quot;off&quot;时表示没有任何日志信息被输出 param [* child] : 创建 level 对象时传递给类构造方法的参数 12ref [#REQUIRED attribute] : 一个 appender 元素的名字的引用appender-ref 元素没有子元素 1param 元素在创建对象时为类的构造方法提供参数。 它可以成为 appender、layout、filter、errorHandler、level、categoryFactory 和 root 等元素的 子元素。 name and value [#REQUIRED attributes] : 提供参数的一组名值对 param 元素没有子元素 下面是对应 的几个Appender的基本配置，相比之下不同的Appender配置时会多出相应的&lt;param name=&quot;&quot; value = &quot;&quot;/&gt;标签。 1234567891011121314consoleAppender:&lt;appender name=&quot;console.log&quot; class=&quot;org.apache.log4j.ConsoleAppender&quot;&gt; &lt;layout ... &gt; ... ... &lt;/layout&gt; &lt;/appender&gt;FileAppender:&lt;appender name=&quot;file.log&quot; class=&quot;org.apache.log4j.FileAppender&quot;&gt;&lt;param name=&quot;File&quot; value=&quot;/tmp/log.txt&quot; /&gt; &lt;param name=&quot;Append&quot; value=&quot;false&quot; /&gt; &lt;layout ... &gt; ... ... &lt;/layout&gt; &lt;/appender&gt; RollingFileAppender:&lt;appender name=&quot;rollingFile.log&quot; class=&quot;org.apache.log4j.RollingFileAppender&quot;&gt;&lt;param name=&quot;File&quot; value=&quot;/tmp/rollingLog.txt&quot; /&gt; &lt;param name=&quot;Append&quot; value=&quot;false&quot; /&gt; &lt;param name=&quot;MaxBackupIndex&quot; value=&quot;2&quot; /&gt; &lt;param name=&quot;MaxFileSize&quot; value=&quot;1024&quot; /&gt; &lt;layout ... &gt; ... ... &lt;/layout&gt; &lt;/appender&gt;PatternLayout:&lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;Conversion&quot; value=&quot;%d [%t] %p - %m%n&quot; /&gt; &lt;/layout&gt; 最详细的demo在log4j官网： https://logging.apache.org/log4j/2.x/manual/migration.html ，同时包含log4j1与log4j2的对比 下面是 http://willow-na.iteye.com/blog/347340 来自的详细配置: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE log4j:configuration SYSTEM &quot;log4j.dtd&quot;&gt; &lt;log4j:configuration xmlns:log4j=&apos;http://jakarta.apache.org/log4j/&apos; &gt; &lt;appender name=&quot;myConsole&quot; class=&quot;org.apache.log4j.ConsoleAppender&quot;&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;[%d&#123;dd HH:mm:ss,SSS\\&#125; %-5p] [%t] %c&#123;2\\&#125; - %m%n&quot; /&gt; &lt;/layout&gt; &lt;!--过滤器设置输出的级别--&gt; &lt;filter class=&quot;org.apache.log4j.varia.LevelRangeFilter&quot;&gt; &lt;param name=&quot;levelMin&quot; value=&quot;debug&quot; /&gt; &lt;param name=&quot;levelMax&quot; value=&quot;warn&quot; /&gt; &lt;param name=&quot;AcceptOnMatch&quot; value=&quot;true&quot; /&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=&quot;myFile&quot; class=&quot;org.apache.log4j.RollingFileAppender&quot;&gt; &lt;param name=&quot;File&quot; value=&quot;D:/output.log&quot; /&gt;&lt;!-- 设置日志输出文件名 --&gt; &lt;!-- 设置是否在重新启动服务时，在原有日志的基础添加新日志 --&gt; &lt;param name=&quot;Append&quot; value=&quot;true&quot; /&gt; &lt;param name=&quot;MaxBackupIndex&quot; value=&quot;10&quot; /&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%p (%c:%L)- %m%n&quot; /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=&quot;activexAppender&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt; &lt;param name=&quot;File&quot; value=&quot;E:/activex.log&quot; /&gt; &lt;param name=&quot;DatePattern&quot; value=&quot;&apos;.&apos;yyyy-MM-dd&apos;.log&apos;&quot; /&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;[%d&#123;MMdd HH:mm:ss SSS\\&#125; %-5p] [%t] %c&#123;3\\&#125; - %m%n&quot; /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- 指定logger的设置，additivity指示是否遵循缺省的继承机制,这里需要注意一下继承机制--&gt; &lt;logger name=&quot;com.runway.bssp.activeXdemo&quot; additivity=&quot;false&quot;&gt; &lt;priority value =&quot;info&quot;/&gt; &lt;appender-ref ref=&quot;activexAppender&quot; /&gt; &lt;/logger&gt; &lt;!-- 根logger的设置--&gt; &lt;root&gt; &lt;priority value =&quot;debug&quot;/&gt; &lt;appender-ref ref=&quot;myConsole&quot;/&gt; &lt;appender-ref ref=&quot;myFile&quot;/&gt; &lt;/root&gt; &lt;/log4j:configuration&gt; 以上配置比较多，具体可以参考官网。 3.Log4j2配置文件Log4j2.xml解析Log4j2没有默认的配置文件，只有缺省默认配置文件，如下: 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;configuration status=&quot;OFF&quot;&gt; &lt;appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n&quot;/&gt; &lt;/Console&gt; &lt;/appenders&gt; &lt;loggers&gt; &lt;root level=&quot;error&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;/root&gt; &lt;/loggers&gt; &lt;/configuration&gt; Log4j2相比于Log4j配置区别如下: log4j 2.x版本不再支持像1.x中的.properties后缀的文件配置方式，2.x版本配置文件后缀名只能为”.xml”,”.json”或者”.jsn”. 系统选择配置文件的优先级(从先到后)如下： .classpath下的名为log4j2-test.json 或者log4j2-test.jsn的文件. .classpath下的名为log4j2-test.xml的文件. .classpath下名为log4j2.json 或者log4j2.jsn的文件. .classpath下名为log4j2.xml的文件. 我们一般默认使用log4j2.xml进行命名。如果本地要测试，可以把log4j2-test.xml放到classpath，而正式环境使用log4j2.xml，则在打包部署的时候不要打包log4j2-test.xml即可。 log4j2的配置组成部分大方向与log4j1类似，这里先贴出从一个比较简单的配置文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot; monitorInterval=&quot;30&quot; strict=&quot;true&quot; schema=&quot;Log4J-V2.2.xsd&quot;&gt; &lt;Properties&gt; &lt;Property name=&quot;filename&quot;&gt;$&#123;date:yyyy-MM-dd&#125;&lt;/Property&gt; &lt;!-- %d&#123;yyyy-MM-dd HH:mm:ss, SSS&#125; : 日志生产时间 %p : 日志输出格式 %c : logger的名称 %m : 日志内容，即 logger.info(&quot;message&quot;) %n : 换行符 %C : Java类名 %L : 日志输出所在行数 %M : 日志输出所在方法名 hostName : 本地机器名 hostAddress : 本地ip地址 --&gt; &lt;Property name=&quot;pattern&quot;&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t] [%-5level] - %l - %msg%n&lt;/Property&gt; &lt;/Properties&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t] [%-5level] %logger&#123;36&#125; - %l - %msg%n&quot;/&gt; &lt;/Console&gt; &lt;!--文件会打印出所有信息，这个log每次运行程序会自动清空，由append属性决定，这个也挺有用的，适合临时测试用--&gt; &lt;File name=&quot;MyFile&quot; fileName=&quot;app.log&quot; append=&quot;true&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n&quot;/&gt; &lt;/File&gt; &lt;!-- 这个会打印出所有的info及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档--&gt; &lt;RollingFile name=&quot;RollingFileInfo&quot; fileName=&quot;$&#123;sys:user.home&#125;/logs/$&#123;filename&#125;-info.log&quot; filePattern=&quot;$&#123;sys:user.home&#125;/logs/$$&#123;date:yyyy-MM-dd&#125;/info-%d&#123;yyyy-MM-dd&#125;-%i.log&quot;&gt; &lt;!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）--&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;pattern&#125;&quot;/&gt; &lt;Policies&gt; &lt;!-- 每24小时更新一次 --&gt; &lt;TimeBasedTriggeringPolicy modulate=&quot;true&quot; interval=&quot;24&quot;/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;10MB&quot;/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max=&quot;2&quot;/&gt; &lt;/RollingFile&gt; &lt;RollingFile name=&quot;RollingFileWarn&quot; fileName=&quot;$&#123;sys:user.home&#125;/logs/$&#123;filename&#125;-warn.log&quot; filePattern=&quot;$&#123;sys:user.home&#125;/logs/$$&#123;date:yyyy-MM-dd&#125;/info-%d&#123;yyyy-MM-dd&#125;-%i.log&quot;&gt; &lt;ThresholdFilter level=&quot;warn&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;pattern&#125;&quot;/&gt; &lt;Policies&gt; &lt;!-- 每24小时更新一次 --&gt; &lt;TimeBasedTriggeringPolicy modulate=&quot;true&quot; interval=&quot;24&quot;/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;10 MB&quot;/&gt; &lt;/Policies&gt; &lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件，这里设置了20 --&gt; &lt;DefaultRolloverStrategy max=&quot;2&quot;/&gt; &lt;/RollingFile&gt; &lt;!-- 指定到系统用户下的目录 --&gt; &lt;RollingFile name=&quot;RollingFileError&quot; fileName=&quot;$&#123;sys:user.home&#125;/logs/$&#123;filename&#125;-error.log&quot; filePattern=&quot;$&#123;sys:user.home&#125;/logs/$$&#123;date:yyyy-MM-dd&#125;/error-%d&#123;yyyy-MM-dd&#125;-%i.log&quot;&gt; &lt;ThresholdFilter level=&quot;error&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;$&#123;pattern&#125;&quot;/&gt; &lt;Policies&gt; &lt;!-- 每24小时更新一次 --&gt; &lt;TimeBasedTriggeringPolicy modulate=&quot;true&quot; interval=&quot;24&quot;/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;10 MB&quot;/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max=&quot;2&quot;/&gt; &lt;/RollingFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;!--&lt;Logger name=&quot;sel4jTest&quot; level=&quot;info&quot;&gt;--&gt; &lt;!--&lt;AppenderRef ref=&quot;MyFile&quot;/&gt;--&gt; &lt;!--&lt;/Logger&gt;--&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;FATAL&quot;&gt;&lt;/logger&gt; &lt;logger name=&quot;org.apache.activemq&quot; level=&quot;FATAL&quot;&gt;&lt;/logger&gt; &lt;Root level=&quot;all&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;!--开启info级别日志--&gt; &lt;!--&lt;AppenderRef ref=&quot;RollingFileInfo&quot;/&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;开启warn级别日志&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;AppenderRef ref=&quot;RollingFileWarn&quot;/&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;开启error级别日志&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;AppenderRef ref=&quot;RollingFileError&quot;/&gt;--&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 具体项目配置和使用时可以参考: Log4j2官网 http://logging.apache.org/log4j/2.x/articles.html log4j2配置博客:http://blog.csdn.net/vergilgeekopen/article/details/61417342 java日志详细博客: https://my.oschina.net/xianggao/blog/523401 4.Logback配置文件解析 （1）logback的介绍 Logback是由log4j创始人设计的另一个开源日志组件,官方网站： http://logback.qos.ch 。它当前分为下面下个模块： logback-core：其它两个模块的基础模块 logback-classic：它是log4j的一个改良版本，同时它完整实现了slf4j API使你可以很方便地更换成其它日志系统如log4j或JDK14 Logging logback-access：访问模块与Servlet容器集成提供通过Http来访问日志的功能 （2）logback的配置 Logback 配置文件的语法非常灵活。正因为灵活，所以无法用 DTD 或 XML schema 进行定义。尽管如此，可以这样描述配置文件的基本结构：以开头，后面有零个或多个元素，有零个或多个元素，有最多一个元素。 默认配置： 如果配置文件 logback-test.xml 和 logback.xml 都不存在，那么 logback 默认地会调用BasicConfigurator ，创建一个最小化配置。最小化配置由一个关联到根 logger 的ConsoleAppender 组成。输出用模式为%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n 的 PatternLayoutEncoder 进行格式化。root logger 默认级别是 DEBUG。 Logback默认配置的步骤： (1). 尝试在 classpath下查找文件logback-test.xml； (2). 如果文件不存在，则查找文件logback.xml； (3). 如果两个文件都不存在，logback用BasicConfigurator自动对自己进行配置，这会导致记录输出到控制台。 （3）logback.xml常用配置详解 以下内容来自:https://www.cnblogs.com/warking/p/5710303.html.参考如下内容时也应该同时参考官方配置文档:https://logback.qos.ch/manual/configuration.html 其实logback日志也是三个方面： 1、根节点&lt;configuration&gt;，包含下面三个属性： scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。例如： 123&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;&lt;!--其他配置省略--&gt; &lt;/configuration&gt; 2、子节点&lt;contextName&gt;：用来设置上下文名称，每个logger都关联到logger上下文，默认上下文名称为default。但可以使用&lt;contextName&gt;设置成其他名字，用于区分不同应用程序的记录。一旦设置，不能修改。例如： 1234&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;contextName&gt;myAppName&lt;/contextName&gt; &lt;!--其他配置省略--&gt; &lt;/configuration&gt; 3、子节点&lt;property&gt;：用来定义变量值，它有两个属性name和value，通过&lt;property&gt;定义的值会被插入到logger上下文中，可以使”${}”来使用变量。 name: 变量的名称 value: 的值时变量定义的值 12345&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;property name=&quot;APP_Name&quot; value=&quot;myAppName&quot; /&gt; &lt;contextName&gt;$&#123;APP_Name&#125;&lt;/contextName&gt; &lt;!--其他配置省略--&gt; &lt;/configuration&gt; 4、子节点：获取时间戳字符串，他有两个属性key和datePattern key: 标识此 的名字； datePattern: 设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循java.txt.SimpleDateFormat的格式。 例如： 12345&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;timestamp key=&quot;bySecond&quot; datePattern=&quot;yyyyMMdd&apos;T&apos;HHmmss&quot;/&gt; &lt;contextName&gt;$&#123;bySecond&#125;&lt;/contextName&gt; &lt;!-- 其他配置省略--&gt; &lt;/configuration&gt; 5、子节点：负责写日志的组件，它有两个必要属性name和class。name指定appender名称，class指定appender的全限定名 5.1、ConsoleAppender 把日志输出到控制台，有以下子节点： &lt;encoder&gt;：对日志进行格式化。（具体参数稍后讲解 ） &lt;target&gt;：字符串System.out(默认)或者System.err 123456789101112&lt;configuration&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg %n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 上述配置表示把&gt;=DEBUG级别的日志都输出到控制台 5.2、FileAppender：把日志添加到文件，有以下子节点： &lt;file&gt;：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。 &lt;append&gt;：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。 &lt;encoder&gt;：对记录事件进行格式化。（具体参数稍后讲解 ） &lt;prudent&gt;：如果是 true，日志会被安全的写入文件，即使其他的FileAppender也在向此文件做写入操作，效率低，默认是 false。 123456789101112 &lt;configuration&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.FileAppender&quot;&gt; &lt;file&gt;testFile.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt; 上述配置表示把&gt;=DEBUG级别的日志都输出到testFile.log 5.3、RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。有以下子节点： &lt;file&gt;：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。 &lt;append&gt;：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。 &lt;rollingPolicy&gt;:当发生滚动时，决定RollingFileAppender的行为，涉及文件移动和重命名。 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。有以下子节点： &lt;fileNamePattern&gt;：必要节点，包含文件名及“%d”转换符，“%d”可以包含一个java.text.SimpleDateFormat指定的时间格式，如：%d{yyyy-MM}。如果直接使用 %d，默认格式是 yyyy-MM-dd。RollingFileAppender的file字节点可有可无，通过设置file，可以为活动文件和归档文件指定不同位置，当前日志总是记录到file指定的文件（活动文件），活动文件的名字不会改变；如果没设置file，活动文件的名字会根据fileNamePattern 的值，每隔一段时间改变一次。“/”或者“\\”会被当做目录分隔符。 &lt;maxHistory&gt;:可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且是6，则只保存最近6个月的文件，删除之前的旧文件注意，删除旧文件是，那些为了归档而创建的目录也会被删除。class=”ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy”： 查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动。只有一个节点::这是活动文件的大小，默认值是10MB。 &lt;prudent&gt;：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。 &lt;triggeringPolicy&gt;: 告知 RollingFileAppender 合适激活滚动。class=”ch.qos.logback.core.rolling.FixedWindowRollingPolicy” 根据固定窗口算法重命名文件的滚动策略。有以下子节点： &lt;minIndex&gt;:窗口索引最小值 &lt;maxIndex&gt;:窗口索引最大值，当用户指定的窗口过大时，会自动将窗口设置为12。 &lt;fileNamePattern&gt;:必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为 mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz 或者 没有log%i.log.zip 1234567891011121314151617181920212223242526272829303132333435363738394041 &lt;configuration&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logFile.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; &lt;!--上述配置表示每天生成一个日志文件，保存30天的日志文件。--&gt; &lt;configuration&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;file&gt;test.log&lt;/file&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.FixedWindowRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;tests.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;3&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt;&lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;FILE&quot;/&gt;&lt;/root&gt;&lt;/configuration&gt; 上述配置表示按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。 &lt;encoder&gt;：对记录事件进行格式化。负责两件事，一是把日志信息转换成字节数组，二是把字节数组写入到输出流。PatternLayoutEncoder 是唯一有用的且默认的encoder ，有一个节点，用来设置日志的输入格式。使用“%”加“转换符”方式，如果要输出“%”，则必须用“\\”对“\\%”进行转义. 5.4、还有SocketAppender、SMTPAppender、DBAppender、SyslogAppender、SiftingAppender，并不常用，这里就不详解了。大家可以参考官方文档（http://logback.qos.ch/documentation.html），还可以编写自己的Appender。 6、子节点：用来设置某一个包或具体的某一个类的日志打印级别、以及指定。仅有一个name属性，一个可选的level和一个可选的addtivity属性。可以包含零个或多个元素，标识这个appender将会添加到这个loger name: 用来指定受此loger约束的某一个包或者具体的某一个类。 level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前loger将会继承上级的级别。addtivity: 是否向上级loger传递打印信息。默认是true。同一样，可以包含零个或多个元素，标识这个appender将会添加到这个loger。 7、子节点&lt;root&gt;:它也是元素，但是它是根loger,是所有的上级。只有一个level属性，因为name已经被命名为”root”,且已经是最上级了。 level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，不能设置为INHERITED或者同义词NULL。 默认是DEBUG 6、常用loger配置 123456789101112&lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt;&lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicBinder&quot; level=&quot;TRACE&quot; /&gt;&lt;logger name=&quot;org.hibernate.type.descriptor.sql.BasicExtractor&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.SQL&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.engine.QueryParameters&quot; level=&quot;DEBUG&quot; /&gt;&lt;logger name=&quot;org.hibernate.engine.query.HQLQueryPlan&quot; level=&quot;DEBUG&quot; /&gt;&lt;!--myibatis log configure--&gt;&lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;TRACE&quot;/&gt;&lt;logger name=&quot;java.sql.Connection&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;java.sql.Statement&quot; level=&quot;DEBUG&quot;/&gt;&lt;logger name=&quot;java.sql.PreparedStatement&quot; level=&quot;DEBUG&quot;/&gt; logback总结 logback的配置，需要配置输出源appender，打日志的loger（子节点）和root（根节点），实际上，它输出日志是从子节点开始，子节点如果有输出源直接输入，如果无，判断配置的addtivity，是否像上级传递，即是否向root传递，传递则采用root的输出源，否则不输出日志 5.写在最后 log4j.properties转logback.xml工具：https://logback.qos.ch/translator/ log4j1/2官网:https://logging.apache.org/log4j/2.x/ slf4j官网: https://www.slf4j.org/ logback官网:https://logback.qos.ch/ 参考博客: https://www.cnblogs.com/warking/p/5710303.html https://my.oschina.net/xianggao/blog/516947","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"Java日志","slug":"Java日志","permalink":"http://www.yq194.top/tags/Java日志/"}]},{"title":"Java日志体系","slug":"Java日志体系","date":"2018-03-01T07:00:59.000Z","updated":"2018-03-05T02:27:26.000Z","comments":true,"path":"2018/03/01/Java日志体系/","link":"","permalink":"http://www.yq194.top/2018/03/01/Java日志体系/","excerpt":"1.Java比较常用的日志组件1.Java中常用日志组件的框架 Java中常用的日志实现框架有Apache的Log4j,Log4j2,Log4j创始人的另一个框架logback以及JDK自带的java.util.logging，他们的对比如下:","text":"1.Java比较常用的日志组件1.Java中常用日志组件的框架 Java中常用的日志实现框架有Apache的Log4j,Log4j2,Log4j创始人的另一个框架logback以及JDK自带的java.util.logging，他们的对比如下: Log4j Apache的一个开放源代码项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件、甚至是套接口服务 器、NT的事件记录器、UNIX Syslog守护进程等；用户也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，用户能够更加细致地控制日志的生成过程。这些可以通过一个 配置文件来灵活地进行配置，而不需要修改程序代码。 Log4j2 log4j2相对于log4j 1.x有了脱胎换骨的变化，其官网宣称的优势有多线程下10几倍于log4j 1.x和logback的高吞吐量、可配置的审计型日志、基于插件架构的各种灵活配置等。 LogBack Logback是由log4j创始人设计的又一个开源日记组件。logback当前分成三个模块：logback-core,logback- classic和logback-access。logback-core是其它两个模块的基础模块。logback-classic是log4j的一个 改良版本。此外logback-classic完整实现SLF4J API使你可以很方便地更换成其它日记系统如log4j或JDK14 Logging。logback-access访问模块与Servlet容器集成提供通过Http来访问日记的功能。 JULJDK自带日志，用的比较少。 日志框架详情可以参考各框架官网。 2.Java中常用日志接口 Apache Common-Logging 和 SLF4J是Java日志体系中常用的日志接口。用户可以自由选择第三方的日志组件作为具体实现，像log4j，log4j2，logback，或者jdk自带的logging等等。其对比如下: Apache Commons Logging common-logging(之前叫 Jakarta Commons Logging，JCL)是apache提供的一个通用的日志接口。用户可以自由选择第三方的日志组件作为具体实现，像log4j，或者jdk自带的logging， common-logging会通过动态查找的机制，在程序运行时自动找出真正使用的日志库。当然，common-logging内部有一个Simple logger的简单实现，但是功能很弱。所以使用common-logging，通常都是配合着log4j来使用。使用它的好处就是，代码依赖是common-logging而非log4j， 避免了和具体的日志方案直接耦合，在有必要时，可以更改日志实现的第三方库。 commons-logging简单实例如下: 1234567891011import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;public class TestJcl &#123; public static void main(String[] args) &#123; Log log = LogFactory.getLog(TestJcl.class); log.debug(&quot;JCL Test infomation&quot;); &#125;&#125; JCL是基于动态查找的原理来装载内部日志：LogFactory.getLog()方法下的getFactory()方法去动态查找，代码如下: 1234567891011121314151617181920org.apache.commons.logging.impl.LogFactoryImpl下: private static final String LOGGING_IMPL_LOG4J_LOGGER = &quot;org.apache.commons.logging.impl.Log4JLogger&quot;; //默认四种加载定义及顺序 private static final String[] classesToDiscover = &#123; LOGGING_IMPL_LOG4J_LOGGER, &quot;org.apache.commons.logging.impl.Jdk14Logger&quot;, &quot;org.apache.commons.logging.impl.Jdk13LumberjackLogger&quot;, &quot;org.apache.commons.logging.impl.SimpleLog&quot; &#125;;discoverLogImplementation()方法中: //动态查找并通过反射加载 for(int i=0; i&lt;classesToDiscover.length &amp;&amp; result == null; ++i) &#123; //该createLogFromClass是具体的加载及查找逻辑 result = createLogFromClass(classesToDiscover[i], logCategory, true); &#125; LogFactory 内部装载日志系统的流程如下： 首先，从VM中寻找org.apache.commons.logging.LogFactory 属性配置。 否则，利用JDK1.3 开始提供的service 发现机制，会扫描classpah 下的META-INF/services/org.apache.commons.logging.LogFactory文件，若找到则装载里面的配置，使用里面的配置。 否则，从Classpath 里寻找commons-logging.properties ，找到则根据里面的配置加载。 否则，使用默认的配置：如果能找到Log4j 则默认使用log4j 实现，如果没有则使用JDK14Logger 实现，再没有则使用commons-logging 内部提供的SimpleLog 实现。 这里也表明了只要使用了Commons-logging(jcl)，就一定会有日志实现匹配上，有log4j就使用log4j,没有log4j就会找jdk14Logger.（桥接情况不考虑的话，当然log4j也要存在配置文件） SLF4J slf4j全称为Simple Logging Facade for JAVA，java简单日志门面。类似于Apache Common-Logging，是对不同日志框架提供的一个门面封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。但是，他在编译时静态绑定真正的Log库。使用SLF4J时，如果你需要使用某一种日志实现，那么你必须选择正确的SLF4J的jar包的集合（各种桥接包和适配器包）。 slf4j简单实例如下: 1234567891011import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class TestSlf4j &#123;public static Logger logger = LoggerFactory.getLogger(TestSlf4j.class); public static void main(String[] args) &#123; logger.debug(&quot;slf4j测试信息&quot;); &#125;&#125; 关于slf4j的静态绑定: SLF4J 会在编译时会绑定import org.slf4j.impl.StaticLoggerBinder，有多种方案时会根据pom.xml中加载的类先后来选择日志框架; 该类里面实现对具体日志方案的绑定接入。任何一种基于slf4j 的日志实现框架都要有一个这个类。 slf4j 与 common-logging 比较 common-logging通过动态查找的机制，在程序运行时自动找出真正使用的日志库。由于它使用了ClassLoader寻找和载入底层的日志库， 导致了象OSGI这样的框架无法正常工作，因为OSGI的不同的插件使用自己的ClassLoader。 OSGI的这种机制保证了插件互相独立，然而却使Apache Commons-Logging无法工作。 slf4j在编译时静态绑定真正的Log库,因此可以再OSGI中使用。另外，SLF4J 支持参数化的log字符串，避免了之前为了减少字符串拼接的性能损耗而不得不写的if(logger.isDebugEnable())，现在你可以直接写：logger.debug(“current user is: {}”, user)。拼装消息被推迟到了它能够确定是不是要显示这条消息的时候，但是获取参数的代价并没有幸免。 3.日志集成方案1. JCL(Commons-Logging)集成方案 从JCL加载源码可以了解到只有静态加载方式中几种集成形式: 如果加入了log4j，优先走log4j,其次走JDK14日志，最后才是SimpleLog。由于是动态加载适配找到日志实现，当一个应用中有多个classloader时，jcl日志会失效，比如OSGI。 JCL组合Log4j pom.xml： 123456789101112131415&lt;dependencies&gt; &lt;!-- jcl --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 简单的log4j.properties: 1234log4j.appender.console= org.apache.log4j.ConsoleAppenderlog4j.appender.console.layout= org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern= [%-5p][%-22d&#123;yyyy/MM/dd HH:mm:ssS&#125;][%l]%n%m%nlog4j.rootCategory=debug,console 代码: 12345678910import org.apache.log4j.Logger;public class TestJcl &#123; static Logger logger = Logger.getLogger(TestJcl.class); public static void main(String[] args) &#123; logger.info(&quot;jcl combine log4j info!!&quot;); &#125;&#125; JCL组合jul(java.util.logging) 上面的pom.xml中去掉log4j和去掉log4j.properties,让jcl动态选择jdk14即可。代码: 12345678910import java.util.logging.Logger;public class TestJul &#123; static Logger logger = Logger.getLogger(&quot;com.xxx&quot;); public static void main(String[] args) &#123; logger.info(&quot;Jdk logger!!!&quot;); &#125;&#125; 2. SLF4J集成方案 slf4j集成方案显得更加通用，同时还可以与jcl进行适配。 这里仅仅是一个简单的图示或者说是比较常用的集成方式，更加详细的可以参照slf4j官网:https://logback.qos.ch/documentation.html. 官方集成示例如下: 官方日志桥接和适配方式如下: jcl,log4j和jul适配到slf4j再接入底层日志框架(如logback),如上图中左上 jcl,jul适配到slf4j再桥接到log4j再接入底层框架，如左上图右 jcl,jul适配到slf4j再桥接到jdk14底层框架，如左上图左 3. slf4j错误集成导致的循环(堆栈溢出 slf4j桥接slf4j-log4j12到底层log4j框架，但log4j框架又通过log4j-over-slf4j适配到了slf4j导致死循环，启动时栈溢出。 4.示例： 将spring日志全使用log4j2 将原本使用log4j的spring日志转到slf4j的log4j2上去，spring原本日志接口使用的是jcl,转换状态如下: 如果说一个单体应用内的两个模块之间日志不同，也可以借用slf4j来达到日志统一，这样的好处是不用修改任何原有模块的代码。 4. 总结刚开始对于Java日志总是各种搞不清，不过对整个体系及发展全面了解后，对于应用中的日志使用和集成方案都能做到心中有X数。下面是参考资料(有些文字copy自参考资料，侵删) http://www.blogjava.net/daiyongzhi/archive/2014/04/13/412364.html 这篇文章参考并copy了部分框架概述 http://www.iqiyi.com/w_19rw75p16p.html java日志视频 http://mvnrepository.com/artifact/org.slf4j Maven仓库找包 https://logback.qos.ch/documentation.html SLF4J官网","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"Java日志","slug":"Java日志","permalink":"http://www.yq194.top/tags/Java日志/"}]},{"title":"JVM GC 笔记","slug":"JVM-GC-笔记","date":"2018-01-31T08:19:12.000Z","updated":"2018-01-31T09:06:52.000Z","comments":true,"path":"2018/01/31/JVM-GC-笔记/","link":"","permalink":"http://www.yq194.top/2018/01/31/JVM-GC-笔记/","excerpt":"","text":"JVM GC笔记 链接地址: https://github.com/IlilIliI/practice-in-java/tree/master/practice-javase-basic/src/main/java/com/github/IlilIliI/jvm/doc","categories":[{"name":"JVM","slug":"JVM","permalink":"http://www.yq194.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://www.yq194.top/tags/JVM/"}]},{"title":"Java集合系列(五):PriorityQueue优先队列","slug":"Java集合系列-五-PriorityQueue优先队列","date":"2018-01-07T12:56:06.000Z","updated":"2018-01-09T07:23:25.000Z","comments":true,"path":"2018/01/07/Java集合系列-五-PriorityQueue优先队列/","link":"","permalink":"http://www.yq194.top/2018/01/07/Java集合系列-五-PriorityQueue优先队列/","excerpt":"1. PriorityQueue概述: PriorityQueue类实现了Queue接口，她的作用是：能保证每次取出的元素都是队列中权值最小的元素。 遵守了Queue接口的约定：不能存储null值。 PriorityQueue类非线程同步，需要线程同步可使用PriorityBlockingQueue类。 底层实现是数组,以数组的形式维护了一个二叉堆，通过该堆来维护权重。 2. 关于PriorityQueue下的二叉堆: 二叉堆有如下特性： 任意一个节点的值总是不大于（最大堆）或者不小于（最小堆）其父节点的值 堆是一棵完全二叉树 而利用数组来存储这个堆，父节点与左右孩子节点的数组下标会有如下规律： leftNode = 2 * parentNode + 1 rightNode = 2 * parentNode + 2 parentNode = (index - 1) / 2","text":"1. PriorityQueue概述: PriorityQueue类实现了Queue接口，她的作用是：能保证每次取出的元素都是队列中权值最小的元素。 遵守了Queue接口的约定：不能存储null值。 PriorityQueue类非线程同步，需要线程同步可使用PriorityBlockingQueue类。 底层实现是数组,以数组的形式维护了一个二叉堆，通过该堆来维护权重。 2. 关于PriorityQueue下的二叉堆: 二叉堆有如下特性： 任意一个节点的值总是不大于（最大堆）或者不小于（最小堆）其父节点的值 堆是一棵完全二叉树 而利用数组来存储这个堆，父节点与左右孩子节点的数组下标会有如下规律： leftNode = 2 * parentNode + 1 rightNode = 2 * parentNode + 2 parentNode = (index - 1) / 2 leftNode表示左孩子的数组下标,rightNode表示右孩子的下标,parentNode表示父节点的数组下标,index表示任意某一非空节点的数组下标。下面是一个堆的示意图: 对比上图和对应的下标规律就可以很清晰的看出父节点与子节点之间的关系。那么堆的创建过程是怎么样的呢？实际上，每添加一个元素，就会进行权重的比较，从而将元素置为符合二叉堆特性的合适的位置,下图表示的是一个堆的创建过程： 在PriorityQueue中，通过Comparable接口来实现元素之间的比较，从而得到元素的优先级。如果没有指定Comparable接口,那PriorityQueue将会按照默认规则比较，且实现的堆为最小堆。 3. PriorityQueue源码解析(JDK1.8.0_131): 首先PriorityQueue底层为Object[] queue,有如下7个构造方法: 123456789101112131415//空构造，默认数组大小11public PriorityQueue();//指定初始大小public PriorityQueue(int initialCapacity);//指定比较器，但不指定初始大小public PriorityQueue(Comparator&lt;? super E&gt; comparator);//指定比较器和初始大小public PriorityQueue(int initialCapacity, Comparator&lt;? super E&gt; comparator) ;//指定集合内容来构造public PriorityQueue(Collection&lt;? extends E&gt; c);//指定某一个PriorityQueue的内容来构造 public PriorityQueue(PriorityQueue&lt;? extends E&gt; c);//指定SortedSet的内容来构造public PriorityQueue(SortedSet&lt;? extends E&gt; c); 如果传入的是PriorityQueue或SortedSet实例，需要对类型和容量大小进行判断，进行相应的扩容或类型处理。 PriorityQueue的创建 如果是初始化指定是某集合如Collection&lt;? extends E&gt; c,那PriorityQueue创建时会从插入最后一个元素的父节点位置开始建堆；否则，就会按照offer()方法来边添加元素边调堆结构创建堆。下面是指定集合时创建堆所调用的方法： 123456private void heapify() &#123; //最后一个元素的父节点,siftDown方法见poll()方法解析 for (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--) //每一个父节点一层一层往下与左右孩子节点比较 siftDown(i, (E) queue[i]);&#125; add()和offer()方法 add()和offer()方法区别在于返回值和抛出异常的不同，这里其实是一样的，重点关注插入元素的操作。以下面add(10)这个操作为例(这里是最大堆,最小堆最大堆原理一样): 源码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); modCount++; //size是queue的元素个数 int i = size; if (i &gt;= queue.length) //创建一个更大的数组把原queue复制过去 grow(i + 1); size = i + 1; if (i == 0) queue[0] = e; else //下一个数组位置加入元素 siftUp(i, e); return true;&#125;//根据有没comparator分开处理 private void siftUp(int k, E x) &#123; if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x);&#125;//添加新元素并保证原有堆的结构不被破坏private void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; //k = 0 停止，也就是parent = 0(最小/最大推顶)处停止 while (k &gt; 0) &#123; //往上找父节点:parentNode = (index - 1) / 2 int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; //如果比较大(小)，不满足交换,直接跳出循环,表示已找到该元素的合适位置 if (key.compareTo((E) e) &gt;= 0) break; //与父节点交换元素 queue[k] = e; //k变成parent的下标，不为0就继续循环while k = parent; &#125; queue[k] = key;&#125; offer操作实际上把当前要加入的元素在加入的同时保证堆结构的原有特性，从k开始，与每层的父节点进行比较直到key.compareTo((E) e)条件满足,不满足时比较到 k = 0处(parent处)停止。siftUp()表示要么是按自然顺序比较，要么是按比较器比较。 element()和peek()方法 element和peek都表示返回堆中权重最大(最小)的元素，且不删除该元素。前者失败时抛出异常，后者失败时返回null,其他方面无区别。不删除元素，意味着只找元素返回，比较简单。如下: 源码: 12345//parent = 0 即可@SuppressWarnings(&quot;unchecked&quot;)public E peek() &#123; return (size == 0) ? null : (E) queue[0];&#125; remove()和poll()方法 与前面的一样poll操作删除元素并返回元素值,失败时与remove仅是返回值与抛出异常的不同。这里主要关注删除元素后，堆的结构变化如何保证： 源码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public E poll() &#123; if (size == 0) return null; int s = --size; modCount++; //返回为0下标的元素 E result = (E) queue[0]; E x = (E) queue[s]; //删除最后一个元素,用最后一个元素与s = 0位置的元素互换，因为最后一个一般是极大(或小)值 queue[s] = null; if (s != 0) //如果不是堆中最后一个元素，就要调整堆结构 siftDown(0, x); return result;&#125;//根据比较不同来调用，具体实现基本一致private void siftDown(int k, E x) &#123; if (comparator != null) siftDownUsingComparator(k, x); else siftDownComparable(k, x);&#125;//调整堆结构private void siftDownComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; //取一半大小比较,因为没有跟叶子节点比较的机会 int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; //k的左孩子 : leftNode = 2 * parentNode + 1，这里假设右边是要交换的 int child = (k &lt;&lt; 1) + 1; // assume left child is least Object c = queue[child]; //k的右孩子 int right = child + 1; //取左右孩子节点中大(或小)的节点 if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) //交换right为k c = queue[child = right]; //找到了比x大(或小)的元素，跳出循环 if (key.compareTo((E) c) &lt;= 0) break; queue[k] = c; //k继续向下左右孩子节点找应该交换的直到k = half停止 k = child; &#125; queue[k] = key;&#125; 先将删除元素x与第0个元素互换，再拿这个元素调用siftDown(0,x)。siftDown(int k, E x)方法，该方法的作用是从k指定的位置开始，将x逐层向下与当前点的左右孩子中较小的(较大)那个交换，直到x小于(大于)或等于左右孩子中的任何一个为止。。而上图中当4节点与8节点交换后，8节点跟7节点交换而不跟6节点交换的原因就在这里(这里是最大堆)。 * Collection接口下的remove(Object o) 该方法是Collection接口中的，不算Queue接口方法，只是继承下来了。当执行该方法时可能会使用堆结构发生改变，所以要调用siftDown()方法调整堆结构，仍然是一层一层往下与左右孩子节点比，找到合适的位置。如果remove的是最后一个元素，则直接干掉；如果不是最后一个，就要调整堆。 源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public boolean remove(Object o) &#123; int i = indexOf(o); if (i == -1) return false; else &#123; removeAt(i); return true; &#125;&#125; private E removeAt(int i) &#123; // assert i &gt;= 0 &amp;&amp; i &lt; size; modCount++; int s = --size; //是最后一个元素 if (s == i) // removed last element queue[i] = null; else &#123; E moved = (E) queue[s]; queue[s] = null; //与最后一个元素交换,并一层一层向下与左右孩子节点比较 siftDown(i, moved); //如果执行siftDown方法向下比较后位置没变，说明该元素是该子树的最小(最大)元素，需要执行上调方 if (queue[i] == moved) &#123; //现原来被删除的位置相同，就往上与父节点比较 siftUp(i, moved); if (queue[i] != moved) return moved; &#125; &#125; return null;&#125;private void siftUp(int k, E x) &#123; if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x);&#125;private void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; while (k &gt; 0) &#123; //找父节点：parentNode = (index - 1) / 2 int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (key.compareTo((E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = key;&#125; 只需要往下比较就能调整好位置: 往下比较好，发现回到原来位置，此时需要往上与父节点比较: 4. 总结: 时间复杂度：offer(),poll(), remove() and add()方法时间复杂度为O(logn);remove(Object obj)和contains()方法需要O(n)时间复杂度;peek()、element()和size()常数时间; 存储堆的数组是无序的，有序输出需要Arrays.sort() 不能存储null元素且线程不安全 参考链接: http://blog.csdn.net/u011116672/article/details/50997622 https://github.com/CarpenterLee/JCFInternals/blob/master/markdown/8-PriorityQueue.md 3Q and End!!!!!!!!!!!","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"http://www.yq194.top/tags/Java集合/"}]},{"title":"Java集合系列(四):Queue,Stack和Deque","slug":"Java集合系列-四-Queue-Stack和Deque","date":"2018-01-06T17:14:51.000Z","updated":"2018-01-07T13:00:56.000Z","comments":true,"path":"2018/01/07/Java集合系列-四-Queue-Stack和Deque/","link":"","permalink":"http://www.yq194.top/2018/01/07/Java集合系列-四-Queue-Stack和Deque/","excerpt":"对比Queue(接口),Stack(类)和Queue(接口)之间的实现，将有利于更好的了解其实现体系及原理。 1. Queue,Stack和Deque之间的区别: 通过LinkedList的类结构层次和源码可以了解到LinkedList既可以当作Queue又可以当作Deque（”double ended queue”的简称,发音”Deck”），而在JDK集合类中还有一个Stack类表示栈（父类是Vector），但推荐使用的ArrayDeque（Deque的子类）这个以数组为底层实现的双端队列来表示栈。 2. JDK中Queue接口与Deque接口的各自主要方法:","text":"对比Queue(接口),Stack(类)和Queue(接口)之间的实现，将有利于更好的了解其实现体系及原理。 1. Queue,Stack和Deque之间的区别: 通过LinkedList的类结构层次和源码可以了解到LinkedList既可以当作Queue又可以当作Deque（”double ended queue”的简称,发音”Deck”），而在JDK集合类中还有一个Stack类表示栈（父类是Vector），但推荐使用的ArrayDeque（Deque的子类）这个以数组为底层实现的双端队列来表示栈。 2. JDK中Queue接口与Deque接口的各自主要方法: Queue的主要方法概要 抛出异常 返回指定值 Insert add(e) offer(e) Remove remove() poll() Examine element() peek() 其中，无论作为队列FIFO还是堆栈LIFO，都是通过调用remove()或poll()来移除的元素，返回被移除的元素。offer()通过返回null/false来表示插入元素成功与否，add()通过检查异常来判断；element()和peek()也同样如此，不过他们表示的是只取头元素，而不删除。Queue通常应当不存储null元素(LinkedList可以存储null)。 Deque双端队列的主要方法概要 头元素(head) 尾元素(tail) 抛出异常 返回指定值 抛出异常 返回指定值 Insert addFirst() offerFirst() addLast() offerLast() Remove removeFirst() poolFirst() removeLast() poolLast() Examine getFirst() peekFirst() getList() peekLast() 因为Deque是双端队列，一个引用head指向头,一个引用tail指向尾，所以两端都可以添加，移除和获得元素。同样地，当进行操作时也有以抛出异常 和返回true/false来标识操作成功与否。Deque的子类应当不存储null元素。 Stack栈(是类而不是接口)的主要方法概要 push(e) pop() peek() Stack类的主要是三个方法push(e)元素入栈，pop()元素出栈并删除栈顶元素,peek()元素出栈但不删除栈顶元素。同时，Stack继承自Vector类，是线程同步类(但全是方法上加synchronized来同步，性能不是很好),其继承体系如下: 123public class Stack&lt;E&gt; extends Vector&lt;E&gt; &#123; ...&#125; 可以存储null元素,已不推荐使用该类作为栈使用,推荐使用Deque的子类实现: 1Deque&lt;E&gt; deque = new ArrayDeque&lt;&gt;(); 3. JDK中Queue接口，Deque接口与Stack类的方法对比: Deque与Queue相对应的接口： Queue Method Equivalent Deque Method 对应操作的说明 add(e) addLast(e) 向队尾插入元素，失败则抛出异常 offer(e) offerLast(e) 向队尾插入元素，失败则返回false remove() removeFirst() 获取并删除队首元素，失败则抛出异常 poll() pollFirst() 获取并删除队首元素，失败则返回null element() getFirst() 获取但不删除队首元素，失败则抛出异常 peek() peekFirst() 获取但不删除队首元素，失败则返回null Deque与Stack对应的接口： Stack Method Equivalent Deque Method 对应操作的说明 push(e) addFirst(e) 向栈顶插入元素，失败则抛出异常 无 offerFirst(e) 向栈顶插入元素，失败则返回false pop() removeFirst() 获取并删除栈顶元素，失败则抛出异常 无 pollFirst() 获取并删除栈顶元素，失败则返回null peek() peekFirst() 获取但不删除栈顶元素，失败则抛出异常 无 peekFirst() 获取但不删除栈顶元素，失败则返回null Deque接口中的方法主要是添加/删除/查看三类操作，与Queue接口和Stack类在这三个操作方面进行类比就能很好的分清这些方法。总之，很好区分的是Deque接口既能当队列又能当栈，Stack类就是JDK实现的栈，Queue接口就队列接口高层抽象。前面有解析Queue的实现LinkedList类，接下来就是Deque的实现ArrayDeque。 4. ArrayDeque类的源码解析(JDK1.8.0_131): ArrayDeque底层实现是数组transient Object[] elements;有head指向头部第一元素的位置，tail指向尾部第一个可插入元素的位置，而且底层数组利用System.arraycopy()来进行扩容。所以综合来说，ArrayDeque底层实现应该是循环数组。 123456//底层存储的数组transient Object[] elements; //指向首端位置，head可能为负transient int head;//指向尾端位置，tail不一定总比head大transient int tail; 如上图，随着不断的对数组进行操作，head和tail的位置不断的在发生变化。下面来看一些基本操作的方法: addFirst(e)往首部添加元素 如上添加 10 这个元素，addFirst(e)往首部添加是head在移动，具体源码如下: 12345678910public void addFirst(E e) &#123; if (e == null) throw new NullPointerException(); //给数组填充值,这里如果head为负的话，通过 //(head - 1) &amp; (elements.length - 1)操作能取成正值 elements[head = (head - 1) &amp; (elements.length - 1)] = e; //进行容量大小判断 if (head == tail) doubleCapacity();&#125; 这里需要注意(1).数组容量大小 (2).数组head或tail(addLast)取非负值的问题。添加元素如addFisrt,addLast都是先赋值再进行head==tail的判断,因为tail永远指向下一个可添加元素的位置。其实主要原因还是在elements.length - 1这个位置做了手脚，看下面的源码: 12345678910111213141516171819202122232425 //空构造函数默认数组大小16，而非空构造会调用如下方法 private void allocateElements(int numElements) &#123; // MIN_INITIAL_CAPACITY 为 8 int initialCapacity = MIN_INITIAL_CAPACITY; // Find the best power of two to hold elements. // Tests &quot;&lt;=&quot; because arrays aren&apos;t kept full. //如果传入numElements &lt; 8,那构造数组大小为8 if (numElements &gt;= initialCapacity) &#123; initialCapacity = numElements; //下面的操作会把initialCapacity变成接近于 //numElements附近的值(2的K次方) //比如 numElements = 9或10或14， //initialCapacity都会变成16,依此类推 initialCapacity |= (initialCapacity &gt;&gt;&gt; 1); initialCapacity |= (initialCapacity &gt;&gt;&gt; 2); initialCapacity |= (initialCapacity &gt;&gt;&gt; 4); initialCapacity |= (initialCapacity &gt;&gt;&gt; 8); initialCapacity |= (initialCapacity &gt;&gt;&gt; 16); initialCapacity++; if (initialCapacity &lt; 0) // Too many elements, must back off initialCapacity &gt;&gt;&gt;= 1;// Good luck allocating 2 ^ 30 elements &#125; elements = new Object[initialCapacity];&#125; 由于上面的无符号位移和异或操作会把initialCapacity变成2的k次方,相应的elements.length - 1的二进制永远是1111111...,再进行类似于addFirst(e)中的(head - 1) &amp; (elements.length - 1)操作，&amp;(与操作，1&amp;1时才为1)操作前缀不管是不是负值都会变成非负值，从而保证了head移动到取负值时也能把head变成相应的非负值,同时&amp;操作也保证了不越出elements.length这个界限。 addLast(e)往尾部添加元素 123456789 public void addLast(E e) &#123; if (e == null) throw new NullPointerException(); //先赋值 elements[tail] = e; //检查tail越界情况，addLast移动的是tail if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head) doubleCapacity();&#125; 这里需要看一下doubleCapacity()这个扩容操作: 123456789101112131415161718192021private void doubleCapacity() &#123; assert head == tail; int p = head; int n = elements.length; // head右边元素个数 int r = n - p; // number of elements to the right of p //原数组长度的2位 int newCapacity = n &lt;&lt; 1; if (newCapacity &lt; 0) throw new IllegalStateException(&quot;Sorry, deque too big&quot;); Object[] a = new Object[newCapacity]; //先复制head右边（图绿色部分） System.arraycopy(elements, p, a, 0, r); //再左边部分(图黄色部分) System.arraycopy(elements, 0, a, r, p); //数组替换 elements = a; //head，tail重新初始位置 head = 0; tail = n; &#125; 扩容操作就是容量扩充一倍，然后把head和tail相等位置的部分分别先head往右再tail往左复制过来，并初始化head=0,tail=length-1即可。 *peekFirst() peekFirst()的作用是返回但不删除Deque首端元素，也即是head位置处的元素，直接返回elements[head]即可。 123public E peekFirst() &#123; return elements[head]; // elements[head] is null if deque empty&#125; pollFirst() pollFirst用于删除首部元素，并将该元素返回。 123456789101112public E pollFirst() &#123; int h = head; @SuppressWarnings(&quot;unchecked&quot;) E result = (E) elements[h]; // Element is null if deque empty if (result == null) return null; elements[h] = null; // Must null out slot //重新定位head head = (h + 1) &amp; (elements.length - 1); return result; &#125; peekLast() peekLast()的作用是返回但不删除Deque尾端元素，也即是tail位置前面的那个元素。 123public E peekLast() &#123; return elements[(tail - 1) &amp; (elements.length - 1)];&#125; pollLast() pollLast()的作用是删除并返回Deque尾端元素，也即是tail位置前面的那个元素。 123456789public E pollLast() &#123; int t = (tail - 1) &amp; (elements.length - 1);//tail的上一个位置 E result = elements[t]; if (result == null)//null值意味着deque为空 return null; elements[t] = null;//let GC work tail = t; return result;&#125; 其他一系列操作基本上是基于以上操作，就不细说了。 本文参考链接: https://github.com/CarpenterLee/JCFInternals/blob/master/markdown/4-Stack%20and%20Queue.md http://calvin1978.blogcn.com/articles/collection.html 3Q AND END!!!","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"http://www.yq194.top/tags/Java集合/"}]},{"title":"Java集合系列(三): LinkedList源码笔记","slug":"Java集合系列(三): LinkedList源码笔记","date":"2018-01-02T07:03:18.000Z","updated":"2018-03-01T07:07:03.000Z","comments":true,"path":"2018/01/02/Java集合系列(三): LinkedList源码笔记/","link":"","permalink":"http://www.yq194.top/2018/01/02/Java集合系列(三): LinkedList源码笔记/","excerpt":"1. LinkedList概述及层次结构(JDK1.8.0_131): LinkedList的继承体系中有List接口，Queue接口和Deque接口(double ended queue),表示明了LinkedList既能当作链表又能当作队列(Queue)还能当作栈(Stack);FIFO,LIFO及顺序访问都可以满足，虽然JDK中有Stack(继承自Vector),但官方推荐使用ArrayDeque. LinkedList底层采用双向链表(prev头节点，next尾节点)，元素可以为null,空链表时prev=next=null. LinkedList线程不安全,可以使用Collections.synchronizedList(List list)进行包装. LinkedList插入，删除操作常数时间，顺序访问线性时间.","text":"1. LinkedList概述及层次结构(JDK1.8.0_131): LinkedList的继承体系中有List接口，Queue接口和Deque接口(double ended queue),表示明了LinkedList既能当作链表又能当作队列(Queue)还能当作栈(Stack);FIFO,LIFO及顺序访问都可以满足，虽然JDK中有Stack(继承自Vector),但官方推荐使用ArrayDeque. LinkedList底层采用双向链表(prev头节点，next尾节点)，元素可以为null,空链表时prev=next=null. LinkedList线程不安全,可以使用Collections.synchronizedList(List list)进行包装. LinkedList插入，删除操作常数时间，顺序访问线性时间. 1234// 来自于源码JDK1.8.0_131public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable 2. LinkedList源码解析(JDK1.8.0_131): 只列出一些比较常用的操作和部分方法解析 2.1 属性及定义: 12345678910111213141516171819202122232425262728293031323334//链表长度(节点数量)transient int size = 0;//头节点transient Node&lt;E&gt; first;//尾节点transient Node&lt;E&gt; last;//内部节点类private static class Node&lt;E&gt; &#123; //节点元素 E item; //指定上一节点 Node&lt;E&gt; next; //指向下一节点 Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125;//构造方法:空链表 public LinkedList() &#123;&#125;//构造方法:以集合作为初始链表public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 2.1 几个基本操作所用到的方法源码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143/** 往链表屁股后添加元素*/void linkLast(E e) &#123; //用临时变量l指向尾节点 final Node&lt;E&gt; l = last; //以l作为头节点，e为元素创建新节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //将尾节点指向新节点 last = newNode; //如果是空链表，first=next=新节点 if (l == null) first = newNode; else //否则把原来尾节点的next指向新节点，以确保双链不断 l.next = newNode; //链表长度增加 size++; //修改标记变量增加 modCount++;&#125;/* * 在链表头插入一个元素为e的节点 */ private void linkFirst(E e) &#123; //临时变量f指向头节点 final Node&lt;E&gt; f = first; //以元素e为尾节点创建新节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //头节点指向新节点 first = newNode; //如果是空链，头尾都指向新节点 if (f == null) last = newNode; else //否则原来的头节点的前一节点指向新节点，保证双链不断 f.prev = newNode; size++; modCount++;&#125;//在非null节点succ前插入元素为e的新节点void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null;succ的前驱节点 final Node&lt;E&gt; pred = succ.prev; //构造新节点，前驱pred,后继succ final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); //设置succ的前驱 succ.prev = newNode; //如果前驱pred为空，表示原来succ=first if (pred == null) //现在first = newNode first = newNode; else //否则设置前驱pred的后继节点 pred.next = newNode; size++; modCount++;&#125;/** * 解除非空头节点f，返回f的值 */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null;返回元素 final E element = f.item; //后继节点 final Node&lt;E&gt; next = f.next; //item引用指向null,帮助GC f.item = null; //f节点的next引用指向null,帮助GC f.next = null; // help GC //链表头节点指向f的后继节点 first = next; //如果后继节点为空，链表尾节点设置为null if (next == null) last = null; else //否则把后继节点的前驱与f断开(未删除时本来指向f） next.prev = null; size--; modCount++; return element;&#125;/** * 解除链表的非空尾节点l,返回节点l的值 */private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null;尾节点元素值 final E element = l.item; //拿到l的前驱prev final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC //把链表尾节点指向prev last = prev; //如果prev为null表示删除l后链表空了 if (prev == null) //first指向null first = null; else //否则把prev的后继置为空 prev.next = null; size--; modCount++; return element;&#125;/** * 解除非空节点x，返回x节点的值 */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; //后继 final Node&lt;E&gt; next = x.next; //前驱 final Node&lt;E&gt; prev = x.prev; //x的前驱为空，链表头节点first指向x的后继 if (prev == null) &#123; first = next; &#125; else &#123; //否则前驱的后继指向x的后继next prev.next = next; x.prev = null; &#125; //x的后继为空，链表的尾节点last指向prev if (next == null) &#123; last = prev; &#125; else &#123; //否则x的后继的前驱指向prev next.prev = prev; //x的后继指向空,help gc x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; (1).addFirst()操作 1234public void addFirst(E e) &#123; //见上面的linkFirst源码 linkFirst(e);&#125; (2).addLast()操作 1234public void addLast(E e) &#123; //如上linkLast源码 linkLast(e);&#125; (3).remove()和remove(int index)操作 123456789101112131415161718192021222324252627/** * 这里遍历链表时区分null和非null值的查找，删除链表中第一个查到的节点 */ public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; //使用unlink unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index)); &#125; 删除中间元素 (4).add(int index,E element)操作 12345678910public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) //见上面源码 linkLast(element); else //见上面源码 linkBefore(element, node(index));&#125; (5).get和set操作 12345678910111213141516171819202122232425262728293031//get,set 操作需要check index操作//get操作public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125; //set操作public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;&#125;Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; (5).indexof()操作 1234567891011121314151617public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; 3. 总结: 从LinkedList中的层次结构来看，既有Deque又有Queue,而本篇是以实现List的双向链表来看源码，后面会有用Deque和Queue对比来看LinkedList。实现list,Deque和Queue的方法如下: LinkedList的set,get方法需要从尾或从头遍历链表[if (index &lt; (size &gt;&gt; 1))],add,addLast,addFirst,remove操作都非常快. Apache(org.apache.commons)下有一个TreeList底层用树来实现快速移动指针来达到快速查找的功能,时间复杂度O(log n),但占用内存大。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"http://www.yq194.top/tags/Java集合/"}]},{"title":"Java集合系列(二): ArrayList源码笔记","slug":"Java集合系列(二): ArrayList源码笔记","date":"2017-12-27T09:50:06.000Z","updated":"2018-01-06T17:31:42.000Z","comments":true,"path":"2017/12/27/Java集合系列(二): ArrayList源码笔记/","link":"","permalink":"http://www.yq194.top/2017/12/27/Java集合系列(二): ArrayList源码笔记/","excerpt":"1. ArrayList概述及层次结构(JDK1.8.0_131): ArrayList的底层是对象数组Object[]，可存储null 未指定初始化大小的默认容量大小是10，超过指定容量后ArrayList采用自动扩容，容量为原来的1.5倍(也就是增加了原来的50%)，1.5倍不大不小刚好，2，2.5。。。都会占用内存大 ArrayList的扩容采用的System.arraycopy()进行复制; 底层是数组决定的查找快，增删慢的特性。get（i），set（i，e） 的性能很高，而remove(i,e)，add(i,e)时需要通过System.arraycopy()复制来达移动数组的目的; ArrayList是非线程安全的，需要同步情况下可在构造时生成同步的List实例或采用java.util.concurrent下的并发类：List list = Collections.synchronizedList(new ArrayList(...));CopyOnWriteArrayList list = new CopyOnWriteArrayList();","text":"1. ArrayList概述及层次结构(JDK1.8.0_131): ArrayList的底层是对象数组Object[]，可存储null 未指定初始化大小的默认容量大小是10，超过指定容量后ArrayList采用自动扩容，容量为原来的1.5倍(也就是增加了原来的50%)，1.5倍不大不小刚好，2，2.5。。。都会占用内存大 ArrayList的扩容采用的System.arraycopy()进行复制; 底层是数组决定的查找快，增删慢的特性。get（i），set（i，e） 的性能很高，而remove(i,e)，add(i,e)时需要通过System.arraycopy()复制来达移动数组的目的; ArrayList是非线程安全的，需要同步情况下可在构造时生成同步的List实例或采用java.util.concurrent下的并发类：List list = Collections.synchronizedList(new ArrayList(...));CopyOnWriteArrayList list = new CopyOnWriteArrayList(); 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 2. ArrayList部分源码分析: ArrayList的使用非常多,在下面的分析中会对ArrayList中的set,add,remove等等操作进行源码分析 ArrayList成员变量及作用 123456789101112131415161718//默认数组容量private static final int DEFAULT_CAPACITY = 10;//共享的空数组实例private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//用来表示空ArrayList,当初始add时，用来区分EMPTY_ELEMENTDATA，以便于要扩充多少容量private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//ArrayList的底层存储区，如果是空ArrayList构造时//使用DEFAULTCAPACITY_EMPTY_ELEMENTDATA，当第一个元素添加时会扩展成 DEFAULT_CAPACITY(10)transient Object[] elementData; //当前ArrayList中(数组中)的存储元素数量private int size;//极限容量，文档注释解释:一些VM在阵列中保留一些标题字。 尝试分配较大的数组可能会导致,OutOfMemoryError：请求的数组大小超过VM限制。private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; ArrayList构造函数 123456789101112131415161718//指定初始容量大小public ArrayList(int initialCapacity);//不指定容量，默认是10，在第一次add()操作时会指定public ArrayList();//将指定的c作为初始内容初始化数组public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) //这个构造函数贴出来主要是说明这个bug(已修复），原因是Object[]对象数组getClass()不一定是 //[Ljava.lang.Object,可以参考http://blog.csdn.net/huzhigenlaohu/article/details/51702737 讲解得很清楚 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; ArrayList的扩容和容量判断方法 自动扩容机制: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//将ArrayList的存储容量缩减实际容量,若实际容量为0，则改成默认大小public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125;//如果有必要，增加ArrayList实例的容量，以确保它至少能容纳由最小容量参数指定的元素数量。public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)? 0: DEFAULT_CAPACITY; //上面的操作就是为了判断传入参数与默认容量比较，看是否要扩容 if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125;//还传入容量与默认容量的比较,取两者中大值private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;//与当前底层数组的容量进行比较，如果比默认容量大，就要扩容了private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;//真正扩容的操作private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //1.5倍的扩容体现在这里 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //1.5扩充后，还要比传入容量小 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //就用传入容量与MAX_ARRAY_SIZE比 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) //比MAX_ARRAY_SIZE还要大，再判断 newCapacity = hugeCapacity(minCapacity); //扩容，Arrays中的方法最后会调用System.arraycopy()本地方法进行数组复制 elementData = Arrays.copyOf(elementData, newCapacity);&#125;//最后只能取两个极限Integer.MAX_VALUE或 MAX_ARRAY_SIZE(正常情况肯定不会取到这里来)private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; ArrayList中的add,addAll添加操作 add操作 addAll操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 //在数组屁股后面添加元素，必要时会扩容,返回true表示集合中值因这个操作而变化 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; //在指定位置添加元素，插入位置之后的所有元素全部后移，性能差，代价大 public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125;//在原数组屁股后添加一个集合的所有元素public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; //从指定index插入一个集合c的所有元素，同样性能差，代价大 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; //这里modCount来自于AbstractList，用来标记并发修改，用 //for-each时迭代会出现ConcurrentModificationException异常.同时需要注意的是 //AbstractList是用来最大限度地减少了实现由“随机访问”数据存储（如数组）支持的接口所需的工作，相应的具体实现只要 //需要或有更好的方式会去实现，不然就是复用 ArrayList中的remove操作 remove操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//remove指定位置操作，返回被remove的值 public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) //数组扩容 System.arraycopy(elementData, index+1, elementData, index, numMoved); //清空移动后的位置内容，方便GC elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; //删除指定元素 public boolean remove(Object o) &#123; //如果o为null，删除第一个为null的元素 if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; //真正的删除操作 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; ArrayList中的查找indexof操作 123456789101112131415161718192021222324252627282930//查找操作，查找第一次出现的位置 public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;//删除一定范围内的元素，从fromIndex到toIndexprotected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize;&#125;//lastIndexOf()与indexOf()相差不大，反向查找，不贴代码了 3. ArrayList总结: ArrayList底层的数据结构决定的ArrayList的特性，从数据结构来看就看出的哪些操作性能差，哪些操作性能好，应当在不同的场合使用恰当的集合类才是最佳的。除了上面的一些操作，还有一些如ListIterator listIterator()(List特有的迭代，用的少一点); Iterator iterator();等方法没有解析，代码太长，可以直接去参考源码。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"Java集合","slug":"Java集合","permalink":"http://www.yq194.top/tags/Java集合/"}]},{"title":"Java I/O流(一):字节流","slug":"Java-I-O流-一-字节流","date":"2017-11-07T02:04:14.000Z","updated":"2018-01-04T02:35:53.000Z","comments":true,"path":"2017/11/07/Java-I-O流-一-字节流/","link":"","permalink":"http://www.yq194.top/2017/11/07/Java-I-O流-一-字节流/","excerpt":"Java I/O 流(一) : 字节流 Java中流的原理: 可以把Java中IO(从文件、网络等等读写数据都是IO)想像成连接着程序和数据源之间的管道，我们既可以通过管道把数据输出到数据源，也可以通过管道将数据从数据源读入。(管道中流的就是01010101… 这样的字节数据) 将管道中流进行过滤、包装、转换等操作就产生一系列的装饰流。 Java中的IO流是指字节数据（bytes data）从源对象对按顺序流向目标对象的一种流动形式 当说输入流输出流的时候是站在程序的角度来说的。 输入流:程序将数据从数据源(网络、文件等)读入到程序中(实际是内存中) 输出流:程序将数据从程序(内存)中输出(写入)到数据源(网络、文件等)","text":"Java I/O 流(一) : 字节流 Java中流的原理: 可以把Java中IO(从文件、网络等等读写数据都是IO)想像成连接着程序和数据源之间的管道，我们既可以通过管道把数据输出到数据源，也可以通过管道将数据从数据源读入。(管道中流的就是01010101… 这样的字节数据) 将管道中流进行过滤、包装、转换等操作就产生一系列的装饰流。 Java中的IO流是指字节数据（bytes data）从源对象对按顺序流向目标对象的一种流动形式 当说输入流输出流的时候是站在程序的角度来说的。 输入流:程序将数据从数据源(网络、文件等)读入到程序中(实际是内存中) 输出流:程序将数据从程序(内存)中输出(写入)到数据源(网络、文件等) ​(图片来源于网络) Java流的分类: 字节流 字符流 输入流 InputStream Reader 输出流 OutputStream Writer 按流向可以分为：输入流和输出流 按处理数据单位大小的不同可以分为：字节流和字符流 按处理功能的不同可以分为：节点流(又叫低级流) 和 处理流(又叫高级流，包装流) ​ 字节流将0101001二进制数据以字节(byte)的方式来读，1个字节(byte)是8位(bit)，读的时候按字节来读； ​ 字符流是以字符为单位读，1个字符是2个字节； ​ 节点流就是直接读数据源里面的数据，或者是直接往数据源里面写入数据,用来读取原始的数据； ​ 处理流是包在别的流上面的流，相当于是包到别的管道上面的管道。 下面是InputStream和OutputStream基本api: 1234567891011121314151617181920212223InputStream(输入流): • 主要方法 abstract int read() //读取一个字节数据， 并返回读到的数据，如果返回-1，表示读到了输入流的末尾。 int read(byte[] b) //将数据读入一个字节数组，同时返回实际读取的字节数。如果返回-1，表示读到了输入流的末尾。 int read(byte[] b, int off, int len)//将数据读入一个字节数组，同时返回实际读取的字节数。如果返回-1，表示读到了输入流的末尾。off 指定在数组b中存放数据的起始偏移位置;len指定读取的最大字节数。 • 其它方法 long skip(long n) //在输入流中跳过n个字节，并返回实际跳过的字节数。 int available() //返回在不发生阻塞的情况下，可读 取的字节数。 void close() //关闭输入流，释放和这个流相关的系统资源。 void mark(int readlimit) //在输入流的当前位置放 置一个标记，如果读取的字节数多于readlimit设置的值， 则流忽略这个标记。 void reset() //返回到上一个标记。 boolean markSupported() //测试当前流是否支持mark和reset方法。如果支持，返回true，否则返回false OutputStream(输出流): • 主要方法 abstract void write(int b) //往输出流中写入一个字节。 void write(byte[] b) //往输出流中写入数组b中的所有字节。 void write(byte[] b, int off,int len) //往输出流中写入数组b中从偏移量off开始的len个字节的数据 • 其它方法 void flush() //刷新输出流，强制缓冲区中的输出字节被写出。 void close() //关闭输出流，释放和这个流相关的系统资源。 InputStream及OutputStream继承体系详解: ​ 在详解之前先放上两张图来整体了解InputStream和OutputStream: ​ InputStream体系结构图(常用类,其中StringBufferInputStream已废弃): ​ ​ OutputStream体系结构图(常用类): ​ ​ 从两张继承体系图可以简单理解： ​ (1) 处理不同的数据来源时，按以下方式来理解比较清晰： ​ 想要处理文件时，来一个子类： FileOutputStream和FileInputStream ​ 想要处理对象时，来一个子类：ObjectInputStream和ObjectOutputStream ​ 想要处理线程间通信时，来一个子类：PipeInputStream和PipedOutputStream ​ 想要处理字节数组时，来一个子类：ByteArrayInputStream和ByteOutputStream ​ 最后，想要多个流进行合并，来一个子类：SequenceInputStream ! 节点流和处理流： 下面是对节点流(包含输入流和输出流)的详细说明 : 1). 节点流 ​ 节点流:从特定的地方读写的流类，例如:磁盘或一块内存区域。 处理类型 字节流 字符流 File(文件) FileInputStream ,FileOutputStream FileReader,FileWriter Mermory Array(内存数组) ByteArrayInputStream, ByteArrayOutputStream CharArrayReader,CharArrayWriter Memory String(内存字符串) ———————————————– StringReader,StringWriter Pipe(管道) PipeInputStream,PipeOutputStream PipeReader,PipeWriter ​ • FileInputStream 和 FileOutputStream ==&gt; 用来处理文件: 123456789101112131415161718192021FileInputStream类创建一个能从文件读取字节的InputStream 类，它的两个常用的方法如下:- FileInputStream(String filepath) throw FileNotFoundException //构造方法- FileInputStream(File fileObj) throw FileNotFoundException //构造方法- FileInputStream(FileDescriptor fdObj) //FileDescriptor为文件描述(封装了不同底层文件系统的统一文件句柄)- int read( ) throws IOException //与InputStream的read一致- FileChannel getChannel() //返回与这个流相关的唯一的FileChannel- FileDescriptor getDF() //返回文件句柄 FileOutputStream类创建一个能从文件读取字节的输出流 类，它的两个常用的方法如下:- FileOutputStream(File file) - FileOutputStream(File file, boolean append)//append指示了在对文件读写时是否追加- FileOutputStream(FileDescriptor fdObj)- FileOutputStream(String name)- FileOutputStream(String name, boolean append)- void write(byte[] b)- void write(byte[] b, int off, int len) //写字节数组，off ~ len- void write(int b)//写指定byte​其它的skip(),available(),close()方法与InputStream中api含意基本相同. ​FileInputStream和FileOutputStream用法: 123456789101112131415161718192021/*** FileInputStream 的示例:* 读取某一文件，并将文件输出生成另一新的文件(或输出每一次读取到的字节并打印)* @throws Exception */public static void test() throws Exception &#123; InputStream is = new FileInputStream(new File(\"/Users/leinl/Desktop/aa.gif\")); //InputStream is = new FileInputStream(\"/Users/leinl/Desktop/aa.gif\"); OutputStream os = new FileOutputStream(\"test.gif\"); byte[] buff = new byte[1024]; int length = 0; int i = 0; while ((length = is.read(buff)) != -1)&#123; //String s = new String(buff,0,length); os.write(buff,0,length); i++; &#125; System.out.println(\"使用buff读了\" + i + \"次\"); os.close(); is.close(); &#125; ​ • ByteArrayInputStream 和 ByteArrayOutputStream ==&gt; 用来处理字节数组: 1234567891011121314151617ByteArrayInputStream是把字节数组当成源的输入流,基内部代码实现是维护了一个用于缓存的buff字节数组:- ByteArrayInputStream(byte[] buf) //构造方法- ByteArrayInputStream(byte[] buf, int offset, int length) //构造方法- int read() //从这个流中读取下一个字节(该类中保存了上一个次读取的位置)- int read(byte[] b, int off, int len) //将数据从这个输入流中读取到一个字节数组中ByteArrayOutputStream调用该输出流的write()方法都会把数据写入到该流中的缓存数组中:- ByteArrayOutputStream() //创建一个新字节数组输出流，默认数组大小32- ByteArrayOutputStream(int size)//创建指定大小的字节数组输出流- int size() //返回当前流中buff的大小- byte[] toByteArray() //产生一个的新的字节数组,Arrays.copy来的- String toString() //产生新的字符串，串\b内容来自于流的byte[]- String toString(String charsetName) //生成指定字符集的新字符串- void write(byte[] b, int off, int len) //将off~len的byte[]写入到这个输出流中- void write(int b) //写指定字节到该流中- void writeTo(OutputStream out) //将out流中的字符写入到该中，相当于调用out.write(buf, 0, count) ​​ByteArrayInputStream和ByteArrayOutputStream用法: 12345678910111213141516171819202122232425262728293031/*** ByteArrayInputStream 和 ByteArrayOutputStream测试*/public static void test() throws Exception&#123; String str = \"Hello ByteArrayInputStream!!!!\"; ByteArrayInputStream is = new ByteArrayInputStream(str.getBytes()); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int ch; while ((ch = is.read()) != -1)&#123; int upperCase = Character.toUpperCase(ch); baos.write(upperCase); &#125; byte[] bytes1 = \"哈哈\".getBytes(); //write(buff,off,len) baos.write(bytes1,0,bytes1.length); //write(buff) baos.write(\"嘿嘿\".getBytes()); byte[] bytes = baos.toByteArray(); System.out.println(baos.toString(\"UTF-8\"));//HELLO BYTEARRAYINPUTSTREAM!!!!哈哈嘿嘿 System.out.println(new String(bytes));//HELLO BYTEARRAYINPUTSTREAM!!!!哈哈嘿嘿 System.out.println(baos.size());//84 //write(outputStream os) baos.writeTo(baos); System.out.println(baos.toString()); is.close(); baos.close(); &#125; ​ • PipeInputStream 和 PipeOutputStream ==&gt; 用来处理线程间的通信 管道流，用于线程间的通信。一个线程的PipedInputStream对象从另一个线程的PipedOutputStream对象读取输入。要使管道流有用，必须同时构造管道输入流和管道输出流。 ​ ​ (图片来自于网络) 从api文档注释来看: 管道输入流应该连接到管道输出流;管道输入流提供了写入管道输出流的数据字节,两个流应分别用两个线程来分别使用使用这两个对象,单个线程操作两个流可能会导致死锁。管道输入流包含缓冲区，提供读写分离。如果为连接的管道输出流提供数据字节的线程已经不再存在，那么就说明该管道被破坏。 1234567891011121314151617181920 &apos;PipedInputStream构造方法:&apos; ​ - PipedInputStream() //创建一个还未连接的PipedInputStream​ ​- PipedInputStream(int pipeSize) //创建一个指定大小缓冲区的PipedInputStream(缓冲区用的是byte[])​ - ​PipedInputStream(PipedOutputStream src) //创建一个PipedInputStream以便于连接传入的输出流src - PipedInputStream(PipedOutputStream src, int pipeSize) //创建指定大小缓冲区的PipedInputStream以便 连接到输出流src​ - int available() ​ - void close() ​ - void connect(PipedOutputStream src) //连接输出流​ - int read() int read(byte[] b, int off, int len)​ &apos;PipedOutputStream构造方法:&apos;​ - PipedOutputStream()​ - PipedOutputStream(PipedInputStream snk) //创建输出流以便连接传入的输入流snk​ - void close()​ - void connect(PipedInputStream snk) //连接输入流​ - void flush()​ - void write(byte[] b, int off, int len)​ - void write(int b) ​ PipeInputStream 和 PipeOutputStream具体使用如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class PipedInputStreamTest &#123; public static void main(String[] args) &#123; Send send = new Send(); Receive receive = new Receive(); PipedInputStream pi = receive.getPi(); PipedOutputStream pos = send.getPos(); try &#123; //连接 pos.connect(pi); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //开启线程 send.start(); receive.start(); &#125;&#125;class Receive extends Thread&#123; private PipedInputStream pi = new PipedInputStream(); @Override public void run() &#123; try &#123; byte[] buf = new byte[1024]; int len = pi.read(buf); System.out.println(\"接收消息,消息接收者Receive:\" + new String(buf,0,len)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pi.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public PipedInputStream getPi() &#123; return pi; &#125;&#125;class Send extends Thread&#123; PipedOutputStream pos = new PipedOutputStream(); @Override public void run() &#123; try &#123; String str = \"hello the world\"; pos.write(str.getBytes()); System.out.println(\"发送消息,消息来源于Send:\" + str); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; pos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public PipedOutputStream getPos() &#123; return pos; &#125;&#125; ​ 以上就是几个常见的节点流的详细介绍，下面是处理流介绍: 2). 处理流 ​ . 处理流:”连接”在已存在的流(节点流或处理流)上，通过对数据的处理为程序提供更强大的功能的流类。 处理类型 字节流 字符流 Buffering BufferedInputStream ,BufferedOutputStream BufferedReader,BufferedWriter Filtering FilterInputStream,FilterOutputStream FilterReader,FilterWriter Converting between Bytes And Character ———————————————– InputStreamReader,OutputStreamWriter Object Serialization ObjectInputStream,ObjectOutputStream —————————————— Data Conversion DataInputStream,DataOutputStream —————————————— Counting LineNumberInputStream LineNumberReader Peaking PushbackInputStream PushbackReader Printing PrintStream PrintWriter a). 第一种处理流：对象流• ObjectInputStream 和 ObjectOutputStream ==&gt; 用来处理被序列化的对象 12345-ObjectInputStream(InputStream in) //构造方法​一系列的read方法如:readInt(),readBoolean()…用从in流中的读取各种对象。​-ObjectOutputStream(OutputStream out) //构造方法 ​ 其他公有方法可与ObjectInputStream类比。具体使用见如下代码: 12345678910111213141516171819202122232425262728293031323334public static void test() throws Exception&#123; ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(new File(\"output.txt\"))); byte[] str = \" the world!\".getBytes(); //void write(byte[] buf) oos.write(str); //void write(byte[] buf,int off,int len) oos.write(str,0,str.length); //void write(double val) oos.writeDouble(2.0D); //void write(int val) oos.write(20); oos.writeByte(112); oos.writeChar('C'); oos.writeBoolean(false); oos.close(); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(new File(\"output.txt\"))); byte[] readBytes = new byte[str.length]; ois.read(readBytes); System.out.println(new String(readBytes)); ois.read(readBytes); System.out.println(new String(readBytes)); double v = ois.readDouble(); System.out.println(v); byte i = ois.readByte(); System.out.println(i); byte b = ois.readByte(); System.out.println(b); char c = ois.readChar(); System.out.println(c); boolean b1 = ois.readBoolean(); System.out.println(b1); ois.close(); &#125; b). 第二种处理流：缓冲流​ • SequenceInputStream ==&gt; 用来处理多个流(数据源)的连接 缓冲输入/输出是一个非常普通的性能优化。Java 的BufferedInputStream类允许把任何InputStream 类“包装”成缓冲流,对数据读取提供了缓冲的功能并使它的性能提高 123456​ - public SequenceInputStream(InputStream s1,InputStream s2) //构造方法，提供一个SequenceInputStream，其提供字节读入的来源是s1,s2,初始化时按先s1再s2的顺序。 - public SequenceInputStream(Enumeration&lt;? extends InputStream&gt; e) //构造方法，按顺序读取Enum中的流集合从而初始化一个SequenceInputStream​两个主要的read方法: - int read() //读下一个字节​ - int read(byte[] b, int off, int len)//读指定buf的off-len长度的byte[] 1234567891011121314public static void test() throws Exception&#123; Vector&lt;InputStream&gt; vector = new Vector&lt;&gt;(2); vector.add(new FileInputStream(new File(\"output.txt\"))); vector.add(new ByteArrayInputStream(\"hello\".getBytes())); Enumeration&lt;InputStream&gt; elements = vector.elements(); SequenceInputStream sis = new SequenceInputStream(elements); byte[] buff = new byte[1024]; int len; FileOutputStream fos = new FileOutputStream(new File(\"output2.txt\")); while ((len = sis.read(buff)) != -1)&#123; fos.write(buff,0,len); &#125; fos.close(); &#125; ​","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.yq194.top/categories/Java基础/"}],"tags":[{"name":"IO","slug":"IO","permalink":"http://www.yq194.top/tags/IO/"}]},{"title":"mysql join 详解","slug":"Mysql join types","date":"2017-05-13T14:44:21.000Z","updated":"2018-01-04T02:36:35.000Z","comments":true,"path":"2017/05/13/Mysql join types/","link":"","permalink":"http://www.yq194.top/2017/05/13/Mysql join types/","excerpt":"SQL JOIN是从两个或多个数据库表中检索数据的方法。本文介绍了特定SQL联接中的数据的基本概述。理解SQL连接的流行方式是使用维恩图进行可视化，因此每个示例都有相应的维恩图，适当的SELECT语句和结果表。本文参考链接: ​ https://dev.mysql.com/doc/refman/5.6/en/join.html mysql官方文档 ​ https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins codeproject文章 ​ https://academy.vertabelo.com/blog/sql-joins/ mysql joins ​ http://stevestedman.com/2015/03/mysql-join-types-poster/ 某博客整理的join图 ​ http://stackoverflow.com/questions/5706437/whats-the-difference-between-inner-join-left-join-right-join-and-full-join/6188334#6188334 stackoverflow","text":"SQL JOIN是从两个或多个数据库表中检索数据的方法。本文介绍了特定SQL联接中的数据的基本概述。理解SQL连接的流行方式是使用维恩图进行可视化，因此每个示例都有相应的维恩图，适当的SELECT语句和结果表。本文参考链接: ​ https://dev.mysql.com/doc/refman/5.6/en/join.html mysql官方文档 ​ https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins codeproject文章 ​ https://academy.vertabelo.com/blog/sql-joins/ mysql joins ​ http://stevestedman.com/2015/03/mysql-join-types-poster/ 某博客整理的join图 ​ http://stackoverflow.com/questions/5706437/whats-the-difference-between-inner-join-left-join-right-join-and-full-join/6188334#6188334 stackoverflow 一、一般来说，大致分为如下四类: INNER JOIN (内连接) OUTER [LEFT | RIGHT | FULL] JOIN （外连接） NATURAL JOIN (自然连接) CROSS JOIN （交叉连接） (mysq中有TRAIGHT_JOIN) 值得注意的是内连接和外连接后接的条件操作符可以是”&gt;”,”&lt;”,”=”,”&gt;=”,”&lt;=” 但是,mysql官方文档中是这样写的: ​ MySQL对SELECT语句的table_references(下面的引用)部分和多表DELETE和UPDATE语句支持JOIN语法(具体如下 )： 1234567891011121314151617181920212223242526272829303132333435363738394041table_references: escaped_table_reference [, escaped_table_reference] ...escaped_table_reference: table_reference | &#123; OJ table_reference &#125;table_reference: table_factor | join_tabletable_factor: tbl_name [PARTITION (partition_names)] [[AS] alias] [index_hint_list] | table_subquery [AS] alias | ( table_references )join_table: table_reference [INNER | CROSS] JOIN table_factor [join_condition] | table_reference STRAIGHT_JOIN table_factor | table_reference STRAIGHT_JOIN table_factor ON conditional_expr | table_reference &#123;LEFT|RIGHT&#125; [OUTER] JOIN table_reference join_condition | table_reference NATURAL [&#123;LEFT|RIGHT&#125; [OUTER]] JOIN table_factorjoin_condition: ON conditional_expr | USING (column_list)index_hint_list: index_hint [, index_hint] ...index_hint: USE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] ([index_list]) | IGNORE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] (index_list) | FORCE &#123;INDEX|KEY&#125; [FOR &#123;JOIN|ORDER BY|GROUP BY&#125;] (index_list)index_list: index_name [, index_name] ... 从上来看，主要两个方面: ​ 1.mysql中会有以下join出现: ​ INNER JOIN( 内连接),CROSS JOIN(交叉连接),这两个可以不带ON ​ STRAIGHT_JOIN(直接连接,可带ON也可以不带ON), ​ LEFT|RIGHT|FULL [OUTER] JOIN 左连接或左外连接或全连接, ​ NATURAL [{LEFT|RIGHT} [OUTER]] JOIN 自然连接(左|右) ​ 2.mysql中可以使用USING来处理像ON这样的条件，下面会详细说明。 二、用实例来说明这些JOIN的区别:​ 首先定两张表如下: 12345678 TableB TableA+------+--------+ +------+--------+| b_id | b_name | | a_id | a_name |+------+--------+ +------+--------+| A | apple | | 1 | apple || B | banana | | 2 | orange || C | NULL | | 3 | NULL |+------+--------+ +------+--------+ ​ （一）外连接(左外连接，右外连接，完整外连接) LEFT JOIN: 12345678select * from TableA left join TableB on TableA.a_name = TableB.b_name+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| 1 | apple | A | apple || 2 | orange | NULL | NULL || 3 | NULL | NULL | NULL |+------+--------+------+--------+ left join 以左表主基准,返回左表的全部记录，如果on后面条件匹配，会带出右表的匹配记录,右表中不匹配的列全是NULL。下面为图解: ​ (不难看出:连接出来不等的右边会取一条null记录来给左表对应) {0}. RIGHT JOIN 12345678SELECT * FROM test.TableA RIGHT JOIN test.TableB ON test.TableA.a_name = test.TableB.b_name;+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| 1 | apple | A | apple || NULL | NULL | B | banana || NULL | NULL | C | NULL |+------+--------+------+--------+ 与LEFT JOIN相反 : ![2.pic](/images/2.pic.jpg) {0}. FULL JOIN（不能带ON条件） 1234567891011121314select * from TableA full join TableB;+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| 1 | apple | A | apple || 1 | apple | B | banana || 1 | apple | C | NULL || 2 | orange | A | apple || 2 | orange | B | banana || 2 | orange | C | NULL || 3 | NULL | A | apple || 3 | NULL | B | banana || 3 | NULL | C | NULL |+------+--------+------+--------+ 外连接的full join 及自然连接的natural join不能带on条件，cross join可以带on条件 如果三者都不带条件的情况下就全连接即笛卡尔集！ ​ #### （二）内连接(INNER JOIN) {0}. INNER JOIN 123456select * from TableA inner join TableB on TableA.a_name = TableB.b_name+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| 1 | apple | A | apple |+------+--------+------+--------+ inner join会根据条件匹配找到条件相等的列，它并不像上面的left join 和right join一样返回左或右边表的所有记录。 （三）交叉连接(CROSS JOIN) 5.CROSS JOIN（通常的笛卡尔集） 1234567891011121314select * from TableA cross join TableB;+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| 1 | apple | A | apple || 1 | apple | B | banana || 1 | apple | C | NULL || 2 | orange | A | apple || 2 | orange | B | banana || 2 | orange | C | NULL || 3 | NULL | A | apple || 3 | NULL | B | banana || 3 | NULL | C | NULL |+------+--------+------+--------+ 就是依次把左表的每一列去与右所有列对应，相当于A:2x3, B:2x3 == &gt; 4*9 ; cross join不带条件就笛卡尔集，带条件就会根据条件去掉相应的列!!! （四）自然连接(NATURAL JOIN),应该可以直接分类到外连接包括为左自然连接和右自然连接(需要注意：自然连接不带ON条件) NATURAL JOIN 这个就不用列出了，就是笛卡尔集，也是full join NATRUAL LEFT JOIN|NATRUAL LEFT JOIN natural join分左右应该只是连接时以左或右为基准去连接，实际上连接 的结果与natural join的结果一样。（感觉这个自然连接意义不大） ​ 二、下面再来讨论一些比较特殊但可能很有用的JOINS LEFT JOIN EXCLUDING INNER JOIN 12345678SELECT * FROM TableA LEFT JOIN test.TableB ON TableA.a_name = TableB.b_nameWHERE TableB.b_name IS NULL;+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| 2 | orange | NULL | NULL || 3 | NULL | NULL | NULL |+------+--------+------+--------+ 返回的结果中是左表的结果(不包含两表的交集‘) Right Excluding JOIN1234567mysql&gt; SELECT * FROM TableA RIGHT JOIN TableB ON TableA.a_name = TableB.b_name WHERE TableA.a_name IS NULL;+------+--------+------+--------+| a_id | a_name | b_id | b_name |+------+--------+------+--------+| NULL | NULL | B | banana || NULL | NULL | C | NULL |+------+--------+------+--------+ 返回的结果是右表的集(除去了两表的交集) Outer Excluding JOIN123SELECT * FROM TableA JOIN test.TableB ON TableA.a_name = TableB.b_name WHERE TableA.a_name IS NULL OR TableB.b_name IS NULL;等价于: (Right Excluding JOIN) UNION (LEFT JOIN EXCLUDING INNER JOIN) ​ 返回的是两表的非交集,这里没有数据主要是我表的数据设置有点问题，不过从 https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins 这篇文章及例子可以了解。 最后mysql中有一个STRAIGHT_JOIN,它的表现与INNER JOIN相同，详细请看下面这个博客 : ​ 【MySQL】性能优化之 straight_join 三、总结 :​ 通过以上的分类可以了解到sql join的具体分类及使用,通过整理应该可以更加好的了解sql join以及mysql join的具体形式及用法 .下面放上盗来的图）)： ​ 图1： ​ 图2：下图还包含3表连接的状态 : 注:图中部分出处都有地址注明，请参见文章开头","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.yq194.top/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.yq194.top/tags/MySQL/"}]}]}